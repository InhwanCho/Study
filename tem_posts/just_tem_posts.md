# 벡터간 유사도
text(image, video, voice) -> 수치화 == embedding(임베딩)이라고 불림
== 벡터공간에 text들을 벡터 형태로 표현한 것
<br></br>
벡터간 유사도
1. 거리 기반 : 유클리디안 거리(보통 백터(행)들의 값이 스칼라(0또는1인 경우))

2. 각도 기반 : 코사인 유사도(다차원(행)들의 값이 2이상인 값들로 이루어진 경우)
> ex) 영화1, 영화2에 keywords
>>Money : 1 , 　Love : 1 등장<br>
Money : 100, Love : 100 등장 <br>
영화 1과 2사이의 유사도는 유클리디안 거리로 구해야 유사값을 파악할 수 있음.


# Layout : '추천 시스템'
## 최근접이웃
- 사용자 기반 : 비슷한 고객들이 어떤 상품을 구매했다.
- 아이템 기반 : 어떤 상품을 구매한 고객들은 다음과 같은 상품도 구매했다. <br>
대체로 아이템 기반을 사용하지만, 초기에는 사용이 거의 불가능하다.

# Layout : '자연어 처리'
## Bow(Bag of words) : 단어 가방
- corpus(코퍼스) : 특정 영역에 해당되는 관련 단어 집합(한국어 : 말뭉치)<br>
>법률 코퍼스 : [즉결, 처분, 구속, 피고, 재판, ...]<br>
금융 코퍼스 : [예금, 잔금, 고객, 선물, 증권, ...]

## TF-IDF(Term Frequency *(행렬곱이 아님) Inverse Document Frequency)
- 흔할 말이 아니고 생소한 단어들이 특정 문서에 나타나는 등장횟수
> ex) 문서1-
```markdown
 가 : 1, 나 : 3, 다 : 5
 가 : 1, 나 : 0, 다 : 9
 가 : 1, 나 : 0, 다 : 8
```
TF(DTM) * IDF = TFIDF

# SVM Algorithm

>결정 경계선(decision boundary)을 만들고 그 경계에 따라 값을 나누는 알고리즘

커널트릭
### 선형 SVM
선형 SVM : 커널을 사용하지 않고 데이터를 분류
`비용(C)`을 조절해서 마진의 크기를 조절할 수 있음
커널 트릭 : 선형 분리가 주어진 차원에서 불가능할 경우 -> 고차원으로 데이터를 옮기는 효과를 통해 결정 경계를 찾음.
`비용(C)`과 `gamma`를 조절해서 마진(점과 support vector사이의 거리)을 조절 가능.

주요 파라미터 <u>C</u> , <u>gamma</u>
`C`가 높으면 마진은 작아지고, 학습 에러율은 감소하는 방향으로 경계선을 만듦.<br>
-> 훈련데이터의 정확도는 높아질 수 있지만, 실제 데이터의 분류는 잘 안될 수 있다.

### 가우시안 RBF 커널

# 머신러닝 평가방법
TP(True,True), FP(False, but True), FN(False, False), TN(True, False)
ACC : TP + TN / all (높은게 좋음)  

recall : TP/ TP + FN
**(실제 True인 데이터 중 모델이 True로 예측, 높은게 좋음)**

precisoion : TP / TP + FP
**(예측이 True인 데이터 중에서 실제로 True데이터의 비중, 높은게 좋음)**

F1-score : recall과 precision 의 조화평균

# 데이터 전처리
### 변수별로 데이터를 묶어서 전처리하면 편함 
- 연속형 : 나이, 가격, 점수, ...
- 범주형 : 성별, 애완동물, ...
* 척도(Scale) : 변수 값을 표현하는 수준.
    * `명명척도` : 혈액형(순서X, 사칙연산 X, 빈도수 O)
    * `서열척도` : 직급(순서O, 사칙연산 X, 직급 사이의 간격 일정하지 않음)
    * `등간척도` : 섭씨온도(간격 일정, 연산 O, 섭시 30도씨 but 30도가 10도보다 3배 따듯하지 않다!(영점(기준)이 임의적이다.)
    * `비율척도` : 등간척도 + 절대영점 >> ex) 수심 10미터는 5미터보다 2배 깊다.
- 중심경향치 : 평균, 중위수, 빈도수
- 변산성 측정치 : 분산, 표준편차, 범위, 사분위
### 상관계수 
- 피어슨 상관계수 : 등간/ 비율 척도
- 스피어만 상관계수 : 비선형
- 켄달(kendall) : 비선형, 서열 척도, 표본이 작을경우 효율적이다
> 상관관계가 있다고 반드시 <u>`인과관계`</u>가 있는것이 아니다!!
```python
import scipy.stats as ss
ss.spearmanr(x,y).correlation
ss.kendalltau(x,y).correlation
ss.pearsonr(x,y).statistic
```
- 왜도(skew) : 치우쳐 있는 모양.<br>
왼쪽으로 치우쳐 있으면 positive skewed, 오른쪽이면 negative skewed
    - 왜도>0 : 평균에 비해 많이 큰 값이 존재 (mean > median > mode(최빈수))
    - 왜도<0 : 평균에비해 많이 작은 값이 존재 (mean< median < mode(최빈수))
    - 정규 분포의 경우 (mean == median == mode)
    - Goal : Minimize cost(W,b)
- 첨도(kurtosis) : 뾰족한 정도.<br>
### 공선성
1. 공선성이란? 하나의 독립 변수가 다른 하나의 독립 변수에 의해 예측이 잘 되는 경우(상관성이 높은 경우)(ex. 온도와 체감온도라는 변수가 같이 있는 경우(둘 다 비슷))
다중공선성이란? 하나의 독립 변수가 다른 여러개의 독립 변수에 의해 예측이 잘되는 경우

2. 데이터셋에 (다중)공선성이 있을 경우
- 회귀 계수가 통계적으로 유의(p-values < 0.05)하지 않게 나옴
- 회귀 계수 추정이 잘 안됨 -> 데이터가 변경이 생기면 추정값(예측값)이 크게 달라짐

3. (다중)공선성의 유무 판단 방법
- VIF(Variance Inflation Factor, 분산팽창계수) 확인
- VIF > 10(경우에 따라 5) 인 경우, 다중 공선성이 있다고 판단.(절대적인 값은 아님)

### GC(Garbage Collector)
그냥 GC를 사용하면 되지 왜 공부해야 하나?
GC는 메모리를 자동으로 관리해주는 ‘과정’이다. 당연히 자동으로 메모리를 관리해 주니 사람이 직접 하는 것보다는 최적화가 덜 되어있다. 그래서 공부를 하고 업무에 적용해야 한다는 것이다. 실제로 인스타그램은 Python GC를 사용하지 않는다.
